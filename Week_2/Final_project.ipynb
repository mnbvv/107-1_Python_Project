{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'DateId', 'MemberId', 'OrderGroupCode',\n",
       "       'TrackSourceTypeDef', 'TrackDeviceTypeDef', 'PayProfileTypeDef',\n",
       "       'SalesOrderSlaveId', 'SalePageId', 'IsMajor', 'IsGift',\n",
       "       'IsSalePageGift', 'Quantity', 'UnitPrice', 'PromotionDiscount',\n",
       "       'ECouponId', 'ECouponDiscount', 'SalesOrderSlaveTotalPayment',\n",
       "       'SalesOrderSlaveDateTime', 'SalesOrderReceiverId', 'City', 'District',\n",
       "       'ZipCode', 'StoreName', 'StoreId', 'DeliverTypeDef', 'StatusDef',\n",
       "       'ReturnGoodsDateId', 'CauseDef'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean2 = pd.read_csv('df_clean2.csv', low_memory=False)\n",
    "df_clean2.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 將地區分為北、中、東、南區"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_region = {\"北部\":['臺北','台北','新北','基隆','宜蘭','桃園','新竹'],\n",
    "               \"中部\":['苗栗','臺中','台中','彰化','南投','雲林'],\n",
    "               \"南部\":['嘉義','臺南','台南','高雄','屏東','澎湖'],\n",
    "               \"東部\":['花蓮','台東','臺東']\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>DateId</th>\n",
       "      <th>MemberId</th>\n",
       "      <th>OrderGroupCode</th>\n",
       "      <th>TrackSourceTypeDef</th>\n",
       "      <th>TrackDeviceTypeDef</th>\n",
       "      <th>PayProfileTypeDef</th>\n",
       "      <th>SalesOrderSlaveId</th>\n",
       "      <th>SalePageId</th>\n",
       "      <th>IsMajor</th>\n",
       "      <th>...</th>\n",
       "      <th>SalesOrderReceiverId</th>\n",
       "      <th>City</th>\n",
       "      <th>District</th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>StoreName</th>\n",
       "      <th>StoreId</th>\n",
       "      <th>DeliverTypeDef</th>\n",
       "      <th>StatusDef</th>\n",
       "      <th>ReturnGoodsDateId</th>\n",
       "      <th>CauseDef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20150703</td>\n",
       "      <td>1388133</td>\n",
       "      <td>b'\\xd0_\\x8eby\\xe8\\x88\\xa5\\x85\\xe4\\x15\\nMC\\xeaO...</td>\n",
       "      <td>Web</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>SevenEleven</td>\n",
       "      <td>4457777</td>\n",
       "      <td>1242871</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>1480890</td>\n",
       "      <td>嘉義縣</td>\n",
       "      <td>水上鄉</td>\n",
       "      <td>608.0</td>\n",
       "      <td>中庄門市</td>\n",
       "      <td>910828</td>\n",
       "      <td>SevenEleven</td>\n",
       "      <td>Finish</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20150703</td>\n",
       "      <td>1388133</td>\n",
       "      <td>b'\\xd0_\\x8eby\\xe8\\x88\\xa5\\x85\\xe4\\x15\\nMC\\xeaO...</td>\n",
       "      <td>Web</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>SevenEleven</td>\n",
       "      <td>4457778</td>\n",
       "      <td>1242880</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>1480890</td>\n",
       "      <td>嘉義縣</td>\n",
       "      <td>水上鄉</td>\n",
       "      <td>608.0</td>\n",
       "      <td>中庄門市</td>\n",
       "      <td>910828</td>\n",
       "      <td>SevenEleven</td>\n",
       "      <td>Finish</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20150703</td>\n",
       "      <td>1388133</td>\n",
       "      <td>b'\\xd0_\\x8eby\\xe8\\x88\\xa5\\x85\\xe4\\x15\\nMC\\xeaO...</td>\n",
       "      <td>Web</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>SevenEleven</td>\n",
       "      <td>4457779</td>\n",
       "      <td>1242880</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>1480890</td>\n",
       "      <td>嘉義縣</td>\n",
       "      <td>水上鄉</td>\n",
       "      <td>608.0</td>\n",
       "      <td>中庄門市</td>\n",
       "      <td>910828</td>\n",
       "      <td>SevenEleven</td>\n",
       "      <td>Finish</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>20150703</td>\n",
       "      <td>1388133</td>\n",
       "      <td>b'\\xd0_\\x8eby\\xe8\\x88\\xa5\\x85\\xe4\\x15\\nMC\\xeaO...</td>\n",
       "      <td>Web</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>SevenEleven</td>\n",
       "      <td>4457780</td>\n",
       "      <td>1175574</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>1480890</td>\n",
       "      <td>嘉義縣</td>\n",
       "      <td>水上鄉</td>\n",
       "      <td>608.0</td>\n",
       "      <td>中庄門市</td>\n",
       "      <td>910828</td>\n",
       "      <td>SevenEleven</td>\n",
       "      <td>Finish</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>20150703</td>\n",
       "      <td>365787</td>\n",
       "      <td>b\"\\x04?}pe$m\\x7f\\x85\\xa0y\\x81'e5\\xca\\xbb\\xf9\\x...</td>\n",
       "      <td>Web</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>SevenEleven</td>\n",
       "      <td>4457791</td>\n",
       "      <td>1194488</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>1480896</td>\n",
       "      <td>桃園市</td>\n",
       "      <td>中壢區</td>\n",
       "      <td>320.0</td>\n",
       "      <td>復華門市</td>\n",
       "      <td>114071</td>\n",
       "      <td>SevenEleven</td>\n",
       "      <td>Finish</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    DateId  MemberId  \\\n",
       "0           0  20150703   1388133   \n",
       "1           1  20150703   1388133   \n",
       "2           2  20150703   1388133   \n",
       "3           3  20150703   1388133   \n",
       "4           4  20150703    365787   \n",
       "\n",
       "                                      OrderGroupCode TrackSourceTypeDef  \\\n",
       "0  b'\\xd0_\\x8eby\\xe8\\x88\\xa5\\x85\\xe4\\x15\\nMC\\xeaO...                Web   \n",
       "1  b'\\xd0_\\x8eby\\xe8\\x88\\xa5\\x85\\xe4\\x15\\nMC\\xeaO...                Web   \n",
       "2  b'\\xd0_\\x8eby\\xe8\\x88\\xa5\\x85\\xe4\\x15\\nMC\\xeaO...                Web   \n",
       "3  b'\\xd0_\\x8eby\\xe8\\x88\\xa5\\x85\\xe4\\x15\\nMC\\xeaO...                Web   \n",
       "4  b\"\\x04?}pe$m\\x7f\\x85\\xa0y\\x81'e5\\xca\\xbb\\xf9\\x...                Web   \n",
       "\n",
       "  TrackDeviceTypeDef PayProfileTypeDef  SalesOrderSlaveId  SalePageId  \\\n",
       "0             Mobile       SevenEleven            4457777     1242871   \n",
       "1             Mobile       SevenEleven            4457778     1242880   \n",
       "2             Mobile       SevenEleven            4457779     1242880   \n",
       "3             Mobile       SevenEleven            4457780     1175574   \n",
       "4             Mobile       SevenEleven            4457791     1194488   \n",
       "\n",
       "   IsMajor    ...     SalesOrderReceiverId  City  District  ZipCode  \\\n",
       "0     True    ...                  1480890   嘉義縣       水上鄉    608.0   \n",
       "1     True    ...                  1480890   嘉義縣       水上鄉    608.0   \n",
       "2     True    ...                  1480890   嘉義縣       水上鄉    608.0   \n",
       "3     True    ...                  1480890   嘉義縣       水上鄉    608.0   \n",
       "4     True    ...                  1480896   桃園市       中壢區    320.0   \n",
       "\n",
       "   StoreName  StoreId  DeliverTypeDef  StatusDef ReturnGoodsDateId  CauseDef  \n",
       "0       中庄門市   910828     SevenEleven     Finish               NaN       NaN  \n",
       "1       中庄門市   910828     SevenEleven     Finish               NaN       NaN  \n",
       "2       中庄門市   910828     SevenEleven     Finish               NaN       NaN  \n",
       "3       中庄門市   910828     SevenEleven     Finish               NaN       NaN  \n",
       "4       復華門市   114071     SevenEleven     Finish               NaN       NaN  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_state = df_clean2[df_clean2['City'] == df_clean2['City']]  #過濾nan\n",
    "m_state.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['北部']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_keys(d, seri_state):\n",
    "    \n",
    "    result = list()\n",
    "    for state in seri_state:\n",
    "        locate_flag = 0\n",
    "        for key,value in d.items():\n",
    "            for a in value:            \n",
    "                if a in state:\n",
    "                    result.append(key)\n",
    "                    locate_flag = 1\n",
    "                    break\n",
    "            if locate_flag == 1:\n",
    "                break\n",
    "        if locate_flag == 0:\n",
    "            result.append('not_define')\n",
    "    return result\n",
    "    \n",
    "get_keys(dict_region, ['桃園'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dongdong/.local/lib/python3.5/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "m_state['Area'] = get_keys(dict_region, m_state['City'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_state =  m_state[m_state['Area'] != 'not_define'] # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>City</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>SalePageId</th>\n",
       "      <th>new_DateId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>南部</td>\n",
       "      <td>嘉義縣</td>\n",
       "      <td>1</td>\n",
       "      <td>1242871</td>\n",
       "      <td>2015-07-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>南部</td>\n",
       "      <td>嘉義縣</td>\n",
       "      <td>1</td>\n",
       "      <td>1242880</td>\n",
       "      <td>2015-07-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>南部</td>\n",
       "      <td>嘉義縣</td>\n",
       "      <td>1</td>\n",
       "      <td>1242880</td>\n",
       "      <td>2015-07-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>南部</td>\n",
       "      <td>嘉義縣</td>\n",
       "      <td>1</td>\n",
       "      <td>1175574</td>\n",
       "      <td>2015-07-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>北部</td>\n",
       "      <td>桃園市</td>\n",
       "      <td>1</td>\n",
       "      <td>1194488</td>\n",
       "      <td>2015-07-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Area City  Quantity  SalePageId new_DateId\n",
       "0   南部  嘉義縣         1     1242871 2015-07-03\n",
       "1   南部  嘉義縣         1     1242880 2015-07-03\n",
       "2   南部  嘉義縣         1     1242880 2015-07-03\n",
       "3   南部  嘉義縣         1     1175574 2015-07-03\n",
       "4   北部  桃園市         1     1194488 2015-07-03"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 取出 \"地區、城市、購買數量、物品編號、時間\"\n",
    "m_state['new_DateId']=pd.to_datetime(m_state['DateId'].astype(str), format='%Y%m%d')\n",
    "a0 = pd.Series(m_state['new_DateId'])\n",
    "a1 = pd.Series(m_state['SalePageId'])\n",
    "a2 = pd.Series(m_state['Quantity'])\n",
    "a3 = pd.Series(m_state['City'])\n",
    "a4 = pd.Series(m_state['Area'])\n",
    "\n",
    "data = {'new_DateId':a0,'SalePageId':a1,'Quantity':a2,'City':a3,'Area':a4}\n",
    "item_loc = pd.DataFrame(data)\n",
    "item_loc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City\n",
       "南投縣      74939\n",
       "台中市     815918\n",
       "台北市     705464\n",
       "台南市     407470\n",
       "台東縣      35217\n",
       "嘉義市      55276\n",
       "嘉義縣      68262\n",
       "基隆市      89367\n",
       "宜蘭縣      87111\n",
       "屏東縣     125897\n",
       "彰化縣     201898\n",
       "新北市    1196609\n",
       "新竹市     148414\n",
       "新竹縣     129924\n",
       "桃園市     599553\n",
       "澎湖縣      20190\n",
       "花蓮縣      69475\n",
       "苗栗縣     108647\n",
       "雲林縣      88407\n",
       "高雄市     580556\n",
       "Name: Quantity, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_num = item_loc.groupby(by='City')['Quantity'].sum()\n",
    "city_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = []\n",
    "s0 = []\n",
    "s1 = []\n",
    "for i in range(len(city_num)):\n",
    "    item_sum = ((item_loc[item_loc['City'].str.contains(city_num.keys()[i])==True]).groupby(by='SalePageId')['Quantity'].sum()).sort_values(ascending = False).head()\n",
    "    for j in range(0,5):\n",
    "        name.append((city_num.keys())[i])\n",
    "    s0.append(pd.Series(item_sum.keys()))\n",
    "    s1.append(pd.Series(np.array(item_sum)))\n",
    "b2 = pd.Series(name)\n",
    "b1 = pd.Series(s1)\n",
    "b0 = pd.Series(s0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = []\n",
    "t1 = []\n",
    "for i in range((len(b0))):\n",
    "    t0 = np.hstack((t0,np.array(b0[i])))\n",
    "    t1 = np.hstack((t1,np.array(b1[i])))\n",
    "s0 = pd.Series(t0)\n",
    "s1 = pd.Series(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找出每個縣市最喜歡購買前五名的物品\n",
    "dataa = {'City':b2,'ItemId':s0,'Quantity':s1}\n",
    "item_num_loc = pd.DataFrame(dataa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>ItemId</th>\n",
       "      <th>Quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>南投縣</td>\n",
       "      <td>1830694.0</td>\n",
       "      <td>393.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>南投縣</td>\n",
       "      <td>2336461.0</td>\n",
       "      <td>384.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>南投縣</td>\n",
       "      <td>2294453.0</td>\n",
       "      <td>317.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>南投縣</td>\n",
       "      <td>3830498.0</td>\n",
       "      <td>275.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>南投縣</td>\n",
       "      <td>1119387.0</td>\n",
       "      <td>271.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>台中市</td>\n",
       "      <td>2336461.0</td>\n",
       "      <td>4218.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>台中市</td>\n",
       "      <td>2294453.0</td>\n",
       "      <td>4018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>台中市</td>\n",
       "      <td>1830694.0</td>\n",
       "      <td>3737.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>台中市</td>\n",
       "      <td>1119387.0</td>\n",
       "      <td>3399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>台中市</td>\n",
       "      <td>3830498.0</td>\n",
       "      <td>3063.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  City     ItemId  Quantity\n",
       "0  南投縣  1830694.0     393.0\n",
       "1  南投縣  2336461.0     384.0\n",
       "2  南投縣  2294453.0     317.0\n",
       "3  南投縣  3830498.0     275.0\n",
       "4  南投縣  1119387.0     271.0\n",
       "5  台中市  2336461.0    4218.0\n",
       "6  台中市  2294453.0    4018.0\n",
       "7  台中市  1830694.0    3737.0\n",
       "8  台中市  1119387.0    3399.0\n",
       "9  台中市  3830498.0    3063.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_num_loc.iloc[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - #### 因為有些城市購買的物品相似，所以還是很難看出城市之間不同喜好 ； 因此下一步想做每個城市每個月物品購買隨時間的變化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-44-f8d5d953a735>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-44-f8d5d953a735>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    rr = (item_loc['City'].str.contains(city_num.keys()[i])==True]).sort_values(['new_DateId'],ascending = True)\u001b[0m\n\u001b[0m                                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "name = []\n",
    "item_year = []\n",
    "item_month =[]\n",
    "s0 = []\n",
    "s1 = []\n",
    "year = ['5','6','7','8']\n",
    "month = ['01','02','03','04','05','06','07','08','09','10','11','12']\n",
    "for i in range(len(city_num)):\n",
    "    rr = (item_loc['City'].str.contains(city_num.keys()[i])==True]).sort_values(['new_DateId'],ascending = True)\n",
    "    for q in range(len(year)):\n",
    "        y = year[q]\n",
    "        for r in range(len(month)):\n",
    "            m =  month[r]\n",
    "            item_sum = (rr[(rr['new_DateId']>'201'+y+'-'+m+'-01') & (rr['new_DateId']<('201'+y+'-'+m+'-31'))].groupby(by='SalePageId')['Quantity'].sum()).sort_values(ascending = False).head()\n",
    "            for j in range(0,5):\n",
    "                name.append((city_num.keys())[i])\n",
    "                item_year.append(('201'+y))\n",
    "                item_month.append(m)\n",
    "            s0.append(pd.Series(item_sum.keys()))\n",
    "            s1.append(pd.Series(np.array(item_sum)))\n",
    "b4 = pd.Series(item_year)\n",
    "b3 = pd.Series(item_month)\n",
    "b2 = pd.Series(name)\n",
    "b1 = pd.Series(s1)\n",
    "b0 = pd.Series(s0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(b0),len(b1),len(b2),len(b3),len(b4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_list = []\n",
    "value_list = []\n",
    "value_list1 = []\n",
    "b2_after = []\n",
    "b3_after = []\n",
    "b4_after = []\n",
    "for i in range(len(b0)):\n",
    "    gg = np.array(b0[i])\n",
    "    if len(gg) < 4:        \n",
    "        empty_list.append(i)\n",
    "    if len(gg) > 4:\n",
    "        value_list.append(b0[i])\n",
    "        value_list1.append(b1[i])\n",
    "        for j in range(0,5):\n",
    "            b2_after.append(b2[(i*5+j)])\n",
    "            b3_after.append(b3[(i*5+j)])\n",
    "            b4_after.append(b4[(i*5+j)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = []\n",
    "t1 = []\n",
    "for i in range((len(value_list))):\n",
    "    t0 = np.hstack((t0,np.array(value_list[i])))\n",
    "    t1 = np.hstack((t1,np.array(value_list1[i])))\n",
    "s0 = pd.Series(t0)\n",
    "s1 = pd.Series(t1)\n",
    "s2 = pd.Series(b2_after)\n",
    "s3 = pd.Series(b3_after)\n",
    "s4 = pd.Series(b4_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataaa = {'ItemId':s0,'Quantity':s1,'City':s2,'month':s3,'year':s4}\n",
    "item_num_loc_ = pd.DataFrame(dataaa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_num_loc_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "kk = item_num_loc_[item_num_loc_['City'].str.contains((city_num.keys())[i])==True]\n",
    "kk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ItemId_top = []\n",
    "for i in range(int(len(kk)/5)):\n",
    "    ItemId_top.append((kk.iloc[[(i*5)]])['ItemId'][(i*5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ItemId_top[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - #### 想看物品編號對應的商品，比較容易看出關係"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('Ntu_Orders.csv')\n",
    "df = pd.read_csv('Orders.csv',header = 0,sep = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a =[1162433.0,1194488.0,1270622.0,1348360.0,1460234.0,1504091.0,1597130.0,1597130.0,1783258.0,\n",
    "    1910591.0,1862588.0,1830694.0,1119387.0,1119387.0,2294453.0,2336461.0,2294453.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i= 16\n",
    "aaa = raw_data.loc[raw_data['SalePageId'] == a[i]]\n",
    "aaa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - ### 可能物品編號方式不同，因此找不到相對應的物品名稱"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - ## 想觀察購買物品的數量及種類是否會隨天氣而有所變化\n",
    " - ### Step1 : 做每個城市每天購買的物品最多的\n",
    " - ### Step2 : 與天氣資訊做結合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = []\n",
    "item_year = []\n",
    "item_month =[]\n",
    "item_day =[]\n",
    "s0 = []\n",
    "s1 = []\n",
    "year = ['5','6','7','8']\n",
    "month = ['01','02','03','04','05','06','07','08','09','10','11','12']\n",
    "day = ['01','02','03','04','05','06','07','08','09','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(city_num)): # 得到城市照日期排的資訊\n",
    "    rr = (item_loc[item_loc['City'].str.contains((city_num.keys())[i])==True]).sort_values(['new_DateId'],ascending = True)\n",
    "    for q in range(len(year)):\n",
    "        y = year[q]\n",
    "        for r in range(len(month)):\n",
    "            m =  month[r]\n",
    "            for s in range((len(day)-2)): # 得到某日購買項目最多的前兩名\n",
    "                d = day[s]\n",
    "                d1 = day[s+1]\n",
    "                itemm = (rr[(rr['new_DateId']>('201'+y+'-'+m+'-'+d)) & (rr['new_DateId']<('201'+y+'-'+m+'-'+d1))].groupby(by='SalePageId')['Quantity'].sum()).sort_values(ascending = False)\n",
    "                item_sum = (itemm.head(2))\n",
    "                item_mean = itemm.sum()\n",
    "                if ((len(item_sum) > 1)): # 判斷第一和第二數量，第一大於第二將資料收集起來\n",
    "                    if (item_sum.iloc[0] > item_sum.iloc[1]):\n",
    "                        item_sum = item_sum.iloc[[0]]\n",
    "                        name.append((city_num.keys())[i])\n",
    "                        item_year.append(('201'+y))\n",
    "                        item_month.append((m+d))\n",
    "                        s0.append(pd.Series(item_sum.keys()))\n",
    "                        ave = (np.array(item_sum)/np.array(item_mean))\n",
    "                        s1.append(ave[0])\n",
    "b5 = pd.Series(item_year)\n",
    "b4 = pd.Series(item_month)\n",
    "b3 = pd.Series(item_day)\n",
    "b2 = pd.Series(name)\n",
    "b1 = pd.Series(s1)\n",
    "b0 = pd.Series(s0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_list = []\n",
    "value_list = []\n",
    "value_list1 = []\n",
    "b2_after = []\n",
    "b3_after = []\n",
    "b4_after = []\n",
    "for i in range(len(b0)):\n",
    "    gg = np.array(b0[i])\n",
    "    if len(gg) <= 0:        \n",
    "        empty_list.append(i)\n",
    "    if len(gg) > 0:\n",
    "        value_list.append(b0[i])\n",
    "        value_list1.append(b1[i])\n",
    "        b2_after.append(b2[(i)])\n",
    "        b3_after.append(b4[(i)])\n",
    "        b4_after.append(b5[(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = []\n",
    "t1 = []\n",
    "for i in range((len(value_list))):\n",
    "    t0 = np.hstack((t0,np.array(value_list[i])))\n",
    "    t1 = np.hstack((t1,np.array(value_list1[i])))\n",
    "s0 = pd.Series(t0)\n",
    "s1 = pd.Series(t1)\n",
    "s2 = pd.Series(b2_after)\n",
    "s3 = pd.Series(b3_after)\n",
    "s4 = pd.Series(b4_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataaaa = {'ItemId':s0,'Quantity':s1,'City':s2,'month':s3,'year':s4}\n",
    "item_num_loc_day = pd.DataFrame(dataaaa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "item_num_loc_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_num_loc_day.to_csv('item_num_loc_day.csv', sep=',', encoding='utf-8-sig')\n",
    "# 每個城市每日購買數量最多的品項"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_num_loc_day = pd.read_csv('item_num_loc_day.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_region = {\"北部\":['臺北','台北','新北','基隆','宜蘭','桃園','新竹'],\n",
    "               \"中部\":['苗栗','臺中','台中','彰化','南投','雲林'],\n",
    "               \"南部\":['嘉義','臺南','台南','高雄','屏東','澎湖'],\n",
    "               \"東部\":['花蓮','台東','臺東']\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keys(d, seri_state):\n",
    "    \n",
    "    result = list()\n",
    "    for state in seri_state:\n",
    "        locate_flag = 0\n",
    "        for key,value in d.items():\n",
    "            for a in value:            \n",
    "                if a in state:\n",
    "                    result.append(key)\n",
    "                    locate_flag = 1\n",
    "                    break\n",
    "            if locate_flag == 1:\n",
    "                break\n",
    "        if locate_flag == 0:\n",
    "            result.append('not_define')\n",
    "    return result\n",
    "    \n",
    "get_keys(dict_region, ['桃園'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_num_loc_day['Area'] = get_keys(dict_region, item_num_loc_day['City'])\n",
    "item_num_loc_day =  item_num_loc_day[item_num_loc_day['Area'] != 'not_define'] # \n",
    "\n",
    "# a4 = pd.Series(item_num_loc_day_temp['Area'])\n",
    "\n",
    "# data = {'new_DateId':a0,'SalePageId':a1,'Quantity':a2,'City':a3,'Area':a4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_num_loc_day.head(-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_num_loc_day.to_csv('item_num_loc_day.csv', sep=',', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - ### 合併天氣資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import quote\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用pd.read_html抓取資料表格\n",
    "station_info = pd.read_csv('station_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_info.drop('Unnamed: 0',axis = 1,inplace=True)   #axis:去行（0）或列（1）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationIndexList = station_info.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ 降雨量 ,  溫度 ] = getClimate(site,date,mode)\n",
    "### 需先執行\n",
    "- station_info = pd.read_csv('station_info.csv')\n",
    "- station_info.drop('Unnamed: 0',axis = 1,inplace=True)\n",
    "- stationIndexList = station_info.columns\n",
    "\n",
    "### mode=1 : 較慢但較準，採取人工測站與無人測站，且加入delay防鎖IP\n",
    "### mode=2 : 較快但不準，只採取人工測站，未加入delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClimate(site,date,mode):\n",
    "    print('Site : ' + site)\n",
    "    print('Date : ' + date)\n",
    "    \n",
    "    precpAvgList = list()\n",
    "    tempAvgList = list()\n",
    "    \n",
    "    #台-->臺\n",
    "    if site[0] == '台':\n",
    "        site = '臺'+site[1:] #字串無法直接指定, ex:site[k] = '臺'\n",
    "            \n",
    "    if mode == 1: \n",
    "        for i in range(len(stationIndexList)):       \n",
    "            \n",
    "            #此地區每個測站\n",
    "            if station_info[stationIndexList[i]][2] == site:\n",
    "                \n",
    "                #需要delay才不會被擋\n",
    "                time.sleep(0.11) \n",
    "                \n",
    "                #去指定網址爬取                \n",
    "                print(station_info[stationIndexList[i]][4] + date) #網址\n",
    "                temp=pd.read_html(station_info[stationIndexList[i]][4] + date)\n",
    "                \n",
    "                 #此測站24小時的資料\n",
    "                for j in range(len(temp[1][10][2:])):\n",
    "                    \n",
    "                    #清空\n",
    "                    precpList = list()\n",
    "                    tempList = list() \n",
    "                    \n",
    "                    #讀取，若是X則跳過\n",
    "                    try:\n",
    "                        precpList.append(np.float(temp[1][10][j+2]))\n",
    "                        tempList.append(np.float(temp[1][3][j+2]))\n",
    "                    except:\n",
    "                        continue\n",
    "                        \n",
    "                    #求得此測站平均\n",
    "                    precpAvg = np.average(precpList)\n",
    "                    tempAvg = np.average(tempList)\n",
    "                    \n",
    "                #此地區所有測站值\n",
    "                if precpAvg == precpAvg:  #確認是否為nan\n",
    "                    precpAvgList.append(precpAvg)\n",
    "                if tempAvg == tempAvg:\n",
    "                    tempAvgList.append(tempAvg)\n",
    "                    \n",
    "        #算出所有測站平均回傳 \n",
    "        print(\"By mode 1-->\")\n",
    "        print(\"測站的降雨量日平均值 : \" + precpAvgList)\n",
    "        print(\"測站的溫度日平均值 : \" + tempAvgList)\n",
    "        \n",
    "        return np.average(precpAvgList), np.average(tempAvgList)\n",
    "    \n",
    "    else:\n",
    "        for i in range(len(stationIndexList)):\n",
    "            \n",
    "            #此地區每個人工測站\n",
    "            if (station_info[stationIndexList[i]][2] == site) and stationIndexList[i].isdigit():\n",
    "                \n",
    "                #需要delay才不會被擋\n",
    "                time.sleep(0.11) \n",
    "                \n",
    "                #去指定網址爬取\n",
    "                print(station_info[stationIndexList[i]][4] + date) #網址\n",
    "                temp=pd.read_html(station_info[stationIndexList[i]][4] + date)\n",
    "    \n",
    "                 #此測站24小時的資料\n",
    "                for j in range(len(temp[1][10][2:])):\n",
    "                    #清空\n",
    "                    precpList = list()\n",
    "                    tempList = list() \n",
    "                    \n",
    "                    #讀取，若是X則跳過\n",
    "                    try:\n",
    "                        precpList.append(np.float(temp[1][10][j+2]))\n",
    "                        tempList.append(np.float(temp[1][3][j+2]))\n",
    "                    except:\n",
    "                        continue\n",
    "                        \n",
    "                    #求得此測站平均\n",
    "                    precpAvg = np.average(precpList)\n",
    "                    tempAvg = np.average(tempList)\n",
    "                \n",
    "                #此地區所有測站值\n",
    "                if precpAvg == precpAvg:  #確認是否為nan\n",
    "                    precpAvgList.append(precpAvg)\n",
    "                if tempAvg == tempAvg:\n",
    "                    tempAvgList.append(tempAvg)\n",
    "#             else:\n",
    "#                 break\n",
    "        #算出人工測站平均回傳\n",
    "        print(\"By mode 2-->\")\n",
    "        print(\"測站的降雨量日平均值 : \" + str(precpAvgList))\n",
    "        print(\"測站的溫度日平均值 : \" + str(tempAvgList))\n",
    "        \n",
    "        #如果無人工測站，改用mode=1\n",
    "        if not((np.average(precpAvgList) == np.average(precpAvgList)) or (np.average(tempAvgList) == np.average(tempAvgList))):\n",
    "            print(\"mode 2 is fail\")\n",
    "\n",
    "            precpAvgList = list()\n",
    "            tempAvgList = list()\n",
    "            for i in range(len(stationIndexList)):       \n",
    "            \n",
    "                #此地區每個測站\n",
    "                if station_info[stationIndexList[i]][2] == site:\n",
    "\n",
    "                    #需要delay才不會被擋\n",
    "                    time.sleep(0.11) \n",
    "\n",
    "                    #去指定網址爬取\n",
    "                    print(station_info[stationIndexList[i]][4] + date) #網址\n",
    "                    temp=pd.read_html(station_info[stationIndexList[i]][4] + date)\n",
    "\n",
    "                     #此測站24小時的資料\n",
    "                    for j in range(len(temp[1][10][2:])):\n",
    "\n",
    "                        #清空\n",
    "                        precpList = list()\n",
    "                        tempList = list()\n",
    "\n",
    "                        #讀取，若是X則跳過\n",
    "                        try:\n",
    "                            precpList.append(np.float(temp[1][10][j+2]))\n",
    "                            tempList.append(np.float(temp[1][3][j+2]))\n",
    "                        except:\n",
    "                            continue\n",
    "\n",
    "                    #求得此測站平均\n",
    "                    precpAvg = np.average(precpList)\n",
    "                    tempAvg = np.average(tempList)\n",
    "\n",
    "                    #此地區所有測站值\n",
    "                    if precpAvg == precpAvg:  #確認是否為nan\n",
    "                        precpAvgList.append(precpAvg)\n",
    "                    if tempAvg == tempAvg:\n",
    "                        tempAvgList.append(tempAvg)\n",
    "\n",
    "            #算出所有測站平均回傳\n",
    "            print(\"mode 2 改 mode 1-->\")            \n",
    "            print(\"測站的降雨量日平均值 : \" + str(precpAvgList))\n",
    "            print(\"測站的溫度日平均值 : \" + str(tempAvgList))\n",
    "            print(\"\")\n",
    "        return np.average(precpAvgList), np.average(tempAvgList)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(item_num_loc_day_temp[8885:]),len(item_num_loc_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_num_loc_day = item_num_loc_day_temp[13137:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_num_loc_day.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loc_rain_2 = []\n",
    "loc_temp_2 = []\n",
    "for i in range(len(item_num_loc_day)):    \n",
    "    hy = str(item_num_loc_day['year'][i+13137])\n",
    "    hm = str(item_num_loc_day['month'][i+13137])\n",
    "    if len(hm) == 4:\n",
    "        a_date = hy+'-'+hm[0:2]+'-'+hm[-2:]\n",
    "    if len(hm) == 3:\n",
    "        a_date = hy+'-0'+hm[0]+'-'+hm[-2:]\n",
    "    a_loc = item_num_loc_day['City'][i+13137]        \n",
    "    dd = getClimate(a_loc,a_date,2)\n",
    "    loc_rain_2.append(dd[0])    \n",
    "    loc_temp_2.append(dd[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tt1_2 = pd.Series(loc_rain_2)\n",
    "tt2_2 = pd.Series(loc_temp_2)\n",
    "data_2 = {'rain_2':tt1_2,'temp_2':tt2_2}\n",
    "item_num_loc_day_temp_2 = pd.DataFrame(data_2)\n",
    "item_num_loc_day_temp_2.to_csv('item_num_rain_temp_2.csv',sep = ',',encoding='utf-8-sig')\n",
    "item_num_loc_day_temp_2.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(item_num_loc_day_temp_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt1 = pd.Series(loc_rain)\n",
    "tt2 = pd.Series(loc_temp)\n",
    "item_num_loc_day['rain'] = tt1\n",
    "item_num_loc_day['temp'] = tt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_num_loc_day.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = pd.Series(t0)\n",
    "s1 = pd.Series(t1)\n",
    "s2 = pd.Series(b2_after)\n",
    "s3 = pd.Series(b3_after)\n",
    "s4 = pd.Series(b4_after)\n",
    "s5 = pd.Series(loc_rain)\n",
    "s6 = pd.Series(loc_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(s0),len(s1),len(s2),len(s3),len(s4),len(s5),len(s6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataaaaa = {'ItemId':s0,'Quantity':s1,'City':s2,'month':s3,'year':s4,'rain':s5,'temp':s6}\n",
    "item_num_loc_day_temp = pd.DataFrame(dataaaaa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "item_num_loc_day_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_num_loc_day.to_csv('item_num_rate_loc_day_temp.csv',sep = ',',encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(item_num_loc_day_temp_2)):\n",
    "    item_num_loc_day_temp['rain'][i+13137] = tt1_2[i]\n",
    "    item_num_loc_day_temp['temp'][i+13137] = tt2_2[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_num_loc_day = pd.read_csv('item_num_rate_loc_day_temp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_num_loc_day_temp = item_num_loc_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Item_ID num\n",
    "pp = item_num_loc_day_temp.groupby(by='ItemId')['Quantity'].sum()\n",
    "len(pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data if have nan\n",
    "na_rain = (item_num_loc_day_temp[item_num_loc_day_temp.isnull().any(axis=1)]['rain'])\n",
    "na_temp = (item_num_loc_day_temp[item_num_loc_day_temp.isnull().any(axis=1)]['temp'])\n",
    "len(na_rain),len(na_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "na_rain.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [9085,9177,9364,9567,12470,12565,12926]\n",
    "for i in range(len(a)):\n",
    "    n = a[i]\n",
    "    item_num_loc_day_temp['rain'][n] = (item_num_loc_day_temp.iloc[[n-1]]['rain'][n-1]+item_num_loc_day_temp.iloc[[n+1]]['rain'][n+1])/2\n",
    "    item_num_loc_day_temp['temp'][n] = (item_num_loc_day_temp.iloc[[n-1]]['temp'][n-1]+item_num_loc_day_temp.iloc[[n+1]]['temp'][n+1])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "item_num_loc_day_temp[item_num_loc_day_temp.isnull().any(axis=1)]['rain']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - ## Use RNN_LSTM to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "tf.set_random_seed(1)   # set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_num_loc_day_temp = pd.read_csv('item_num_rate_loc_day_temp.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nj = []\n",
    "s5 = pd.Series(np.array(item_num_loc_day_temp['rain']))\n",
    "s6 = pd.Series(np.array(item_num_loc_day_temp['temp']))\n",
    "datb = {'rain':s5,'temp':s6}\n",
    "datbb = pd.DataFrame(datb)\n",
    "nj = np.array(datbb.head(661))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以南投縣為例[0:661]\n",
    "# t = item_num_loc_day_temp.head(661)['year']+item_num_loc_day_temp.head(661)['month'] # 順序\n",
    "t = item_num_loc_day_temp.head(661)['year']+item_num_loc_day_temp.head(661)['month']\n",
    "y_real  =  nj   # 天氣(雨及溫度)\n",
    "plt.plot(t, y_real, 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "lr = 0.001                  # learning rate\n",
    "training_iters = 100        # train step 上限\n",
    "batch_size = 7            \n",
    "n_inputs = 3                # data_feature\n",
    "n_steps = 7                 # time steps\n",
    "n_hidden_units = 128        # neurons in hidden layer\n",
    "n_classes = 1774            # Item_ID num "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create x y placeholder\n",
    "x = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Functions of weight and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    # shape (3, 128)\n",
    "    'in': tf.Variable(tf.random_normal([n_inputs, n_hidden_units])),\n",
    "    # shape (128, 1774)\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_units, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    # shape (128, )\n",
    "    'in': tf.Variable(tf.constant(0.1, shape=[n_hidden_units, ])),\n",
    "    # shape (1774, )\n",
    "    'out': tf.Variable(tf.constant(0.1, shape=[n_classes, ]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Encoder inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN(X, weights, biases):\n",
    "    # 原始的 X 是 3 维数据, 我们需要把它变成 2 维数据才能使用 weights 的矩阵乘法\n",
    "    # X ==> (128 batches * 7 steps, 3 inputs)\n",
    "    X = tf.reshape(X, [-1, n_inputs])\n",
    "\n",
    "    # X_in = W*X + b\n",
    "    X_in = tf.matmul(X, weights['in']) + biases['in']\n",
    "    # X_in ==> (128 batches, 7 steps, 128 hidden) 换回3维\n",
    "    X_in = tf.reshape(X_in, [-1, n_steps, n_hidden_units])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 basic LSTM Cell.\n",
    "lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden_units, forget_bias=1.0, state_is_tuple=True)\n",
    "init_state = lstm_cell.zero_state(batch_size, dtype=tf.float32) # 初始化全零 state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, final_state = tf.nn.dynamic_rnn(lstm_cell, X_in, initial_state=init_state, time_major=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs generate\n",
    "w_out = _weight([n_hiddens, n_output])\n",
    "b_out = _bias([n_output])\n",
    "preds = [tf.add(tf.matmul(decoder_outputs[i], w_out), b_out, name='pred') for i in range(dec_len)]\n",
    "preds, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_loss = 0\n",
    "for _y, _Y in zip(preds, y):\n",
    "    output_loss += tf.reduce_mean(tf.nn.l2_loss(_y - _Y))\n",
    "\n",
    "l_r = 1e-3\n",
    "update_step = tf.train.AdamOptimizer(l_r).minimize(output_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Evaluation function (plotting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sess):\n",
    "    batch_x = [y_real[i].reshape([-1, 1]) for i in range(5)]\n",
    "    batch_y = [y_real[i+5].reshape([-1, 1]) for i in range(5)]\n",
    "    feed_dict = {x[j]:batch_x[j] for j in range(enc_len)}\n",
    "    feed_dict.update({y[j]:batch_y[j] for j in range(enc_len)})\n",
    "    y_pred1 = np.array(sess.run(preds, feed_dict=feed_dict))\n",
    "\n",
    "    batch_x = y_pred1\n",
    "    batch_y = [y_real[i+10].reshape([-1, 1]) for i in range(5)]\n",
    "    feed_dict = {x[j]:batch_x[j] for j in range(enc_len)}\n",
    "    feed_dict.update({y[j]:batch_y[j] for j in range(enc_len)})\n",
    "    y_pred2 = np.array(sess.run(preds, feed_dict=feed_dict))\n",
    "\n",
    "    y_pred = np.vstack([y_pred1, y_pred2]).reshape([-1])\n",
    "    print(len([y_real[4]]+list(y_pred)),len(list(y_pred)))\n",
    "    plt.plot(np.arange(21), y_real[0:21], 'b')\n",
    "    plt.plot(np.arange(21), [y_real[4]]+list(y_pred), '--r')    \n",
    "    plt.legend(['Real', 'Prediction'])\n",
    "    \n",
    "def evaluate2(sess):\n",
    "    batch_x = [y_real[i+3].reshape([-1, 1]) for i in range(5)]\n",
    "    batch_y = [y_real[i+5+3].reshape([-1, 1]) for i in range(5)]\n",
    "    feed_dict = {x[j]:batch_x[j] for j in range(enc_len)}\n",
    "    feed_dict.update({y[j]:batch_y[j] for j in range(enc_len)})\n",
    "    y_pred1 = np.array(sess.run(preds, feed_dict=feed_dict))\n",
    "\n",
    "    batch_x = y_pred1\n",
    "    batch_y = [y_real[i+10+3].reshape([-1, 1]) for i in range(5)]\n",
    "    feed_dict = {x[j]:batch_x[j] for j in range(enc_len)}\n",
    "    feed_dict.update({y[j]:batch_y[j] for j in range(enc_len)})\n",
    "    y_pred2 = np.array(sess.run(preds, feed_dict=feed_dict))\n",
    "\n",
    "    y_pred = np.vstack([y_pred1, y_pred2]).reshape([-1])\n",
    "    plt.plot(np.arange(15), y_real[0+3:15+3], 'b')\n",
    "    plt.plot(np.arange(11)+4, [y_real[4+3]]+list(y_pred), '--r')\n",
    "    plt.legend(['Real', 'Prediction']) \n",
    "    \n",
    "def evaluate3(sess):\n",
    "    batch_x = [y_real[i+5].reshape([-1, 1]) for i in range(5)]\n",
    "    batch_y = [y_real[i+5+5].reshape([-1, 1]) for i in range(5)]\n",
    "    feed_dict = {x[j]:batch_x[j] for j in range(enc_len)}\n",
    "    feed_dict.update({y[j]:batch_y[j] for j in range(enc_len)})\n",
    "    y_pred1 = np.array(sess.run(preds, feed_dict=feed_dict))\n",
    "\n",
    "    batch_x = y_pred1\n",
    "    batch_y = [y_real[i+10+5].reshape([-1, 1]) for i in range(5)]\n",
    "    feed_dict = {x[j]:batch_x[j] for j in range(enc_len)}\n",
    "    feed_dict.update({y[j]:batch_y[j] for j in range(enc_len)})\n",
    "    y_pred2 = np.array(sess.run(preds, feed_dict=feed_dict))\n",
    "\n",
    "    y_pred = np.vstack([y_pred1, y_pred2]).reshape([-1])\n",
    "    plt.plot(np.arange(15), y_real[0+5:15+5], 'b')\n",
    "    plt.plot(np.arange(11)+4, [y_real[4+5]]+list(y_pred), '--r')\n",
    "    plt.legend(['Real', 'Prediction'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "epoch = 100\n",
    "batch_size = n\n",
    "loss_list = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initial prediction\n",
    "plt.figure(figsize=[17, 4])\n",
    "plt.subplot(131)\n",
    "evaluate(sess)\n",
    "plt.subplot(132)\n",
    "evaluate2(sess)\n",
    "plt.subplot(133)\n",
    "evaluate3(sess)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[17, 4])\n",
    "\n",
    "evaluate(sess)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
